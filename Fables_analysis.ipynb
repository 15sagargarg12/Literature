{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import required package to clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Om\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Om\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Om\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting input text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fables_files_name =  os.listdir('Fables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidate fables documents in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_fable =[]\n",
    "\n",
    "for i in fables_files_name:\n",
    "    f = open('./Fables/'+i,'r')\n",
    "    documents_fable.append(f.read())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing text using nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Steps:\n",
    "    # 1. lowercase\n",
    "    # 2. Lammetize. \n",
    "    # 3. Remove stop words.\n",
    "    # 4. Remove punctuations.\n",
    "    # 5. Remove character with the length size of 1.\n",
    "\n",
    "    lowered = str.lower(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(lowered)\n",
    "\n",
    "    words = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            if w not in string.punctuation:\n",
    "                if len(w) > 1:\n",
    "                    lemmatized = lemmatizer.lemmatize(w)\n",
    "                    words.append(lemmatized)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making word tokens at index: 0\n",
      "making word tokens at index: 1\n",
      "making word tokens at index: 2\n",
      "making word tokens at index: 3\n",
      "making word tokens at index: 4\n",
      "making word tokens at index: 5\n",
      "making word tokens at index: 6\n",
      "making word tokens at index: 7\n",
      "making word tokens at index: 8\n",
      "making word tokens at index: 9\n",
      "making word tokens at index: 10\n",
      "making word tokens at index: 11\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each Fable document\n",
    "all_tokens_fable = []\n",
    "for i, document in enumerate(documents_fable):\n",
    "    tokens = preprocess(document)\n",
    "    all_tokens_fable.append(tokens)\n",
    "\n",
    "    print(\"making word tokens at index:\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach 1: using the intersection score- how many words are matching within each document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(word_tokens1, word_tokens2):\n",
    "    # Combine both tokens to find union.\n",
    "    both_tokens = word_tokens1 + word_tokens2\n",
    "    union = set(both_tokens)\n",
    "\n",
    "    # Calculate intersection.\n",
    "    intersection = set()\n",
    "    for w in word_tokens1:\n",
    "        if w in word_tokens2:\n",
    "            intersection.add(w)\n",
    "\n",
    "    score = len(intersection)/len(union)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding similar documents on basis of intersection score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document to The_Ass_and_the_Lapdog.txt based on intersection score is The_Frogs_Desiring_a_King.txt with score value : 0.0952\n",
      "\n",
      "Most similar document to The_Cock_and_the_Pearl.txt based on intersection score is The_Wolf_and_the_Crane.txt with score value : 0.0707\n",
      "\n",
      "Most similar document to The_Dog_and_the_Shadow.txt based on intersection score is The_Fox_and_the_Crow.txt with score value : 0.0526\n",
      "\n",
      "Most similar document to The_Fox_and_the_Crow.txt based on intersection score is The_Man_and_the_Serpent.txt with score value : 0.0909\n",
      "\n",
      "Most similar document to The_Frogs_Desiring_a_King.txt based on intersection score is The_Lion_and_the_Mouse.txt with score value : 0.0966\n",
      "\n",
      "Most similar document to The_Lions_Share.txt based on intersection score is The_Lion_and_the_Mouse.txt with score value : 0.1043\n",
      "\n",
      "Most similar document to The_Lion_and_the_Mouse.txt based on intersection score is The_Man_and_the_Serpent.txt with score value : 0.1182\n",
      "\n",
      "Most similar document to The_Man_and_the_Serpent.txt based on intersection score is The_Lion_and_the_Mouse.txt with score value : 0.1182\n",
      "\n",
      "Most similar document to The_Sick_Lion.txt based on intersection score is The_Lions_Share.txt with score value : 0.0741\n",
      "\n",
      "Most similar document to The_Town_Mouse_and_the_Country_Mouse.txt based on intersection score is The_Frogs_Desiring_a_King.txt with score value : 0.095\n",
      "\n",
      "Most similar document to The_Wolf_and_the_Crane.txt based on intersection score is The_Fox_and_the_Crow.txt with score value : 0.0744\n",
      "\n",
      "Most similar document to The_Wolf_and_the_Lamb.txt based on intersection score is The_Man_and_the_Serpent.txt with score value : 0.0849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    all_scores = []\n",
    "    for j in range(12):\n",
    "        score = calculate_score(all_tokens_fable[i], all_tokens_fable[j])\n",
    "        all_scores.append(score)\n",
    "            \n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for index_score, score in enumerate(all_scores):\n",
    "        if score!=1: # score with 1 is not checked as they are same documents \n",
    "            if highest_score < score:\n",
    "                highest_score = score\n",
    "                highest_score_index = index_score\n",
    "\n",
    "    most_similar_document = fables_files_name[highest_score_index]\n",
    "\n",
    "    print(\"Most similar document to \"+fables_files_name[i]+\" based on intersection score is \"+most_similar_document+\" with score value :\", round(highest_score,4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach 2: using tfidf cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_similarity(to_compare_doc, all_docs,j):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    #Combine the documents.\n",
    "    all_docs.insert(0, to_compare_doc)\n",
    "    embeddings = vectorizer.fit_transform(all_docs)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(embeddings[0:1], embeddings[1:]).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(cosine_similarities):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "\n",
    "    most_similar_document = documents_fable.index(all_docs[highest_score_index+1])\n",
    "    \n",
    "    print(\"Very similar document to \"+ fables_files_name[j]+\" by TF-IDF is \"+fables_files_name[most_similar_document]+\" with the score \", highest_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very similar document to The_Ass_and_the_Lapdog.txt by TF-IDF is The_Sick_Lion.txt with the score  0.38349051245492927\n",
      "Very similar document to The_Cock_and_the_Pearl.txt by TF-IDF is The_Wolf_and_the_Crane.txt with the score  0.2467043574020293\n",
      "Very similar document to The_Dog_and_the_Shadow.txt by TF-IDF is The_Wolf_and_the_Crane.txt with the score  0.30592873783842783\n",
      "Very similar document to The_Fox_and_the_Crow.txt by TF-IDF is The_Lions_Share.txt with the score  0.31079713181798\n",
      "Very similar document to The_Frogs_Desiring_a_King.txt by TF-IDF is The_Lions_Share.txt with the score  0.30538689538476904\n",
      "Very similar document to The_Lions_Share.txt by TF-IDF is The_Sick_Lion.txt with the score  0.3751967072875698\n",
      "Very similar document to The_Lion_and_the_Mouse.txt by TF-IDF is The_Sick_Lion.txt with the score  0.3873801296708266\n",
      "Very similar document to The_Man_and_the_Serpent.txt by TF-IDF is The_Lion_and_the_Mouse.txt with the score  0.3127439040993012\n",
      "Very similar document to The_Sick_Lion.txt by TF-IDF is The_Lion_and_the_Mouse.txt with the score  0.3873801296708265\n",
      "Very similar document to The_Town_Mouse_and_the_Country_Mouse.txt by TF-IDF is The_Lion_and_the_Mouse.txt with the score  0.34958683262947343\n",
      "Very similar document to The_Wolf_and_the_Crane.txt by TF-IDF is The_Lions_Share.txt with the score  0.3416250590824933\n",
      "Very similar document to The_Wolf_and_the_Lamb.txt by TF-IDF is The_Wolf_and_the_Crane.txt with the score  0.2920992048760125\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    all_docs = []\n",
    "    for j in range(12):\n",
    "        if(i!=j):\n",
    "            all_docs.append(documents_fable[j])    \n",
    "    tfidf_similarity(documents_fable[i],all_docs,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# approach 3: using bert algorith of sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_similar(to_compare_doc, all_docs,j):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    #to_compare document\n",
    "    sentences = sent_tokenize(to_compare_doc)\n",
    "    to_compare_embeddings_sentences = model.encode(sentences)\n",
    "    to_compare_embeddings = np.mean(np.array(to_compare_embeddings_sentences), axis=0)\n",
    "    \n",
    "    vectors = []\n",
    "    for i, doc in enumerate(all_docs):\n",
    "\n",
    "        sentences = sent_tokenize(doc)\n",
    "        embeddings_sentences = model.encode(sentences)\n",
    "        embeddings = np.mean(np.array(embeddings_sentences), axis=0)\n",
    "\n",
    "        vectors.append(embeddings)\n",
    "\n",
    "    cosine_similarities = cosine_similarity([to_compare_embeddings], vectors).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(cosine_similarities):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "\n",
    "    most_similar_document = documents_fable.index(all_docs[highest_score_index])\n",
    "    \n",
    "    print(\"Very similar document to \"+ fables_files_name[j]+\" by bert is \"+fables_files_name[most_similar_document]+\" with the score \", highest_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very similar document to The_Ass_and_the_Lapdog.txt by bert is The_Wolf_and_the_Crane.txt with the score  0.6624953\n",
      "Very similar document to The_Cock_and_the_Pearl.txt by bert is The_Fox_and_the_Crow.txt with the score  0.7921164\n",
      "Very similar document to The_Dog_and_the_Shadow.txt by bert is The_Wolf_and_the_Crane.txt with the score  0.7620533\n",
      "Very similar document to The_Fox_and_the_Crow.txt by bert is The_Town_Mouse_and_the_Country_Mouse.txt with the score  0.8256444\n",
      "Very similar document to The_Frogs_Desiring_a_King.txt by bert is The_Sick_Lion.txt with the score  0.79758346\n",
      "Very similar document to The_Lions_Share.txt by bert is The_Sick_Lion.txt with the score  0.84790856\n",
      "Very similar document to The_Lion_and_the_Mouse.txt by bert is The_Town_Mouse_and_the_Country_Mouse.txt with the score  0.8127598\n",
      "Very similar document to The_Man_and_the_Serpent.txt by bert is The_Sick_Lion.txt with the score  0.82803726\n",
      "Very similar document to The_Sick_Lion.txt by bert is The_Lions_Share.txt with the score  0.84790856\n",
      "Very similar document to The_Town_Mouse_and_the_Country_Mouse.txt by bert is The_Fox_and_the_Crow.txt with the score  0.82564443\n",
      "Very similar document to The_Wolf_and_the_Crane.txt by bert is The_Lions_Share.txt with the score  0.8250106\n",
      "Very similar document to The_Wolf_and_the_Lamb.txt by bert is The_Sick_Lion.txt with the score  0.8139425\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    all_docs = []\n",
    "    for j in range(12):\n",
    "        if(i!=j):\n",
    "            all_docs.append(documents_fable[j])    \n",
    "    bert_similar(documents_fable[i],all_docs,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought to try tensorflow, but there is no label available to classify the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I have tried 3 different approaches:\n",
    "### Approach 1: to check the jaccard score: It is score range from 0 to1 using below formula: intersection(a,b)/union(a,b) where a and b are 2 different documents\n",
    "\n",
    "Limitation of this approach is it is just checking common words, semantic meaning is missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: to check the td idf cosine similarity score: check angle between 2 vectors. \n",
    "\n",
    "cosine similarity is good when duplication in data matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3 is the recommended one: used bert : its best method in NLP to understand context heavy texts, Domain knowledge is also considered while selecting this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended content: \n",
    "\n",
    "who viewed The_Ass_and_the_Lapdog should be recommended- The_Wolf_and_the_Crane, The_Lions_Share, The_Sick_Lion\n",
    "\n",
    "who viewed The_Cock_and_the_Pearl should be recommended- The_Fox_and_the_Crow, The_Town_Mouse_and_the_Country_Mouse\n",
    "\n",
    "who viewed The_Dog_and_the_Shadow should be recommended- The_Wolf_and_the_Crane, The_Lions_Share, The_Sick_Lion\n",
    "\n",
    "who viewed The_Fox_and_the_Crow should be recommended- The_Town_Mouse_and_the_Country_Mouse\n",
    "\n",
    "who viewed The_Frogs_Desiring_a_King should be recommended- The_Sick_Lion, The_Lions_Share\n",
    "\n",
    "who viewed The_Lions_Share should be recommended- The_Sick_Lion\n",
    "\n",
    "who viewed The_Lion_and_the_Mouse should be recommended- The_Town_Mouse_and_the_Country_Mouse, The_Fox_and_the_Crow\n",
    "\n",
    "who viewed The_Man_and_the_Serpent should be recommended- The_Sick_Lion, The_Lions_Share\n",
    "\n",
    "who viewed The_Sick_Lion should be recommended- The_Lions_Share\n",
    "\n",
    "who viewed The_Town_Mouse_and_the_Country_Mouse should be recommended- The_Fox_and_the_Crow\n",
    "\n",
    "who viewed The_Wolf_and_the_Crane should be recommended- The_Lions_Share, The_Sick_Lion\n",
    "\n",
    "who viewed The_Wolf_and_the_Lamb should be recommended- The_Sick_Lion, The_Lions_Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
